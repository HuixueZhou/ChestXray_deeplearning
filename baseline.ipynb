{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HW4_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ct_Q8DStWH-_",
        "outputId": "16def573-1df2-4d09-98e3-38883b8bab74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#classify cheXray into normal or pneumonia\n",
        "# This base line use pretrained resnet18 as the baseline model\n",
        "#running in colab\n",
        "#test gpu\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torch.utils\n",
        "import numpy\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "KqLOOJheWSmU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#means and std of all x-ray imgs of this dataset\n",
        "MEAN=[0.48104131770750114, 0.48104131770750114, 0.48104131770750114]\n",
        "STD=[0.23757618012549234, 0.23757618012549234, 0.23757618012549234]\n",
        "\n",
        "class ChestXrayDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, root, image_list_file, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root: root path to image directory.\n",
        "            image_list_file: path to the file containing images\n",
        "                with corresponding labels.\n",
        "            transform: optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        imgs_path = []\n",
        "        labels = []\n",
        "\n",
        "        with open(image_list_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                items = line.split(',')\n",
        "                img_path = os.path.join(root, items[0])\n",
        "                label = [items[1]]\n",
        "\n",
        "                imgs_path.append(img_path)\n",
        "                labels.append(label)\n",
        "\n",
        "        self.imgs_path = imgs_path\n",
        "        self.labels = labels\n",
        "\n",
        "        if transform is None:\n",
        "            # use pre_defined transfer\n",
        "            normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                             [0.229, 0.224, 0.225])#ImageNet means and std\n",
        "\n",
        "            \n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize([320, 320]),\n",
        "                # transforms.RandomResizedCrop(320),\n",
        "                # transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "                 ])\n",
        "\n",
        "            self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index: the index of item\n",
        "\n",
        "        Returns:\n",
        "            image and its label\n",
        "        \"\"\"\n",
        "        img_path = self.imgs_path[index]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        label = torch.FloatTensor(list(map(float, self.labels[index])))\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs_path)\n"
      ],
      "metadata": {
        "id": "ZPuRSZbDWVdE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(num_classes=1,pretrained=True):\n",
        "\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained)\n",
        "\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_features, num_features),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.1),\n",
        "        nn.Linear(num_features, num_classes),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "vZ87YxJ5WbBQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBinaryTensor(out, boundary = 0.5):\n",
        "    zero = torch.zeros_like(out)\n",
        "    one = torch.ones_like(out)\n",
        "    out=torch.where(out > boundary, one, zero)\n",
        "    return out.view(-1)\n"
      ],
      "metadata": {
        "id": "nV2ozrGIMfKA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, dataloader, criterion, total_batch):\n",
        "    model.eval()\n",
        "    counter = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        bar = tqdm(enumerate(dataloader), total=total_batch)\n",
        "        for i, (data, label) in bar:\n",
        "            input = data.clone().detach()\n",
        "            target = label.clone().detach()\n",
        "            if torch.cuda.is_available():\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            output = model(input)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss_sum += loss.item()\n",
        "            counter += 1\n",
        "            bar.set_postfix_str('loss: %.5s' % loss.item())\n",
        "\n",
        "    loss_mean = loss_sum / counter\n",
        "    return loss_mean"
      ],
      "metadata": {
        "id": "WI5nRVdfQG3x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(root,train_data_list, test_data_list,train_batch_size=16, save_model=False, eval_=False,scalar_name='training loss'):\n",
        "    #model\n",
        "    model = get_model()\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "      torch.backends.cudnn.benchmark = True\n",
        "      print(\"using GPU\")\n",
        "\n",
        "    # data\n",
        "    print(\"load data\")\n",
        "    train_data = ChestXrayDataSet(root, train_data_list)\n",
        "    if eval_:\n",
        "      train_data,eval_data=train_test_split(test_size=0.1,shuffle=True)\n",
        "      train_dataloader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True,num_workers=2)\n",
        "      eval_dataloader= DataLoader(eval_data, batch_size=train_batch_size, shuffle=True,num_workers=2)\n",
        "    else:\n",
        "      train_dataloader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True,num_workers=2)\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "   \n",
        "    # training\n",
        "    print(\"training\")\n",
        "    epoches = 5\n",
        "    loss_mean_min = 1e100\n",
        "\n",
        "    for epoch in range(epoches):\n",
        "        train_loss = 0.\n",
        "        train_acc = 0.\n",
        "        running_loss=0.\n",
        "        total_batch = int(len(train_data) / train_batch_size )\n",
        "        bar = tqdm(enumerate(train_dataloader), total=total_batch)\n",
        "\n",
        "        for step, (data, label) in bar:\n",
        "            # train model\n",
        "          torch.set_grad_enabled(True)\n",
        "          batch_x = data.clone().detach().requires_grad_(True)\n",
        "          batch_y = label.clone().detach()\n",
        "          if torch.cuda.is_available():\n",
        "            batch_x = batch_x.cuda()\n",
        "            batch_y = batch_y.cuda()\n",
        "\n",
        "          out = model(batch_x)\n",
        "          loss = criterion(out, batch_y)\n",
        "          train_loss += loss.item()\n",
        "          running_loss += loss.item()\n",
        "          # pred is the expect class\n",
        "          # batch_y is the true label\n",
        "          #pred = torch.max(out, 1)[1]\n",
        "          pred=getBinaryTensor(out)\n",
        "          train_correct = (pred == batch_y.view(-1)).sum()\n",
        "          train_acc += train_correct.item()\n",
        "          if epoch==0 and step==0:\n",
        "            print(pred)\n",
        "            print( batch_y.view(-1))\n",
        "            print(train_correct)\n",
        "            print(train_acc)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          bar.set_postfix_str('loss: %.5s' % loss.item())\n",
        "          \n",
        "          if step % 20 == 19:\n",
        "            print(train_acc,(step+1)*train_batch_size)\n",
        "            print('\\n','Epoch: ', epoch, 'Step', step, 'Train_loss: ', train_loss/(step+1), 'Train acc: ', train_acc/((step+1)*train_batch_size))\n",
        "            writer.add_scalar(scalar_name, running_loss/20, epoch * len(train_dataloader) + step)\n",
        "            running_loss = 0.\n",
        "        \n",
        "        if eval_:\n",
        "          train_min_loss_mean=validation(model, eval_dataloader, criterion, total_batch)\n",
        "        else:\n",
        "          train_min_loss_mean=train_loss/(step+1)\n",
        "          \n",
        "        if train_min_loss_mean<=loss_mean_min:\n",
        "          print('\\n','Update min loss mean','Epoch: ', epoch, 'Step', step,'min loss mean: ', train_loss/(step+1))\n",
        "          time_end=time.strftime('%m-%d-%Hh%Mm')\n",
        "          loss_mean_min=train_min_loss_mean\n",
        "          if save_model:\n",
        "            torch.save({'epoch': epoch + 1,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict()},\n",
        "                       './checkpoints/m_' + time_end + '.pth.tar')\n",
        "\n",
        "            \n",
        "        print('\\n','Epoch: ', epoch, 'Train_loss: ', train_loss / len(train_data), 'Train acc: ',\n",
        "              train_acc / len(train_data))\n",
        "        \n",
        "    #test(root,test_data_list)\n",
        "    # save model\n",
        "    #print(\"saving final model\")\n",
        "    #model_without_ddp = model\n",
        "    #time_end=time.strftime('%m-%d-%Hh%Mm')\n",
        "    #torch.save({'epoch': epoch + 1,\n",
        "                        #'state_dict': model.state_dict(),\n",
        "                        #'optimizer': optimizer.state_dict()},\n",
        "                       #'./checkpoints/final_' + time_end + '.pth.tar')\n"
      ],
      "metadata": {
        "id": "xP4Va3mzWwpx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if save model,set dir root and make checkpoints dir before training\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "#os.mkdir('./checkpoints')"
      ],
      "metadata": {
        "id": "Muomyz8WwEpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H-WRu7pBTE9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#whole dataset\n",
        "root='DATA ROOT'\n",
        "train_data_list='TRAIN_DATA_LIST'\n",
        "test_data_list='TEST_DATA_LIST'\n",
        "train(root,train_data_list, test_data_list)"
      ],
      "metadata": {
        "id": "YFdUOe2m-9Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "qK8ZKP6jb0QV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "y4-EdqE5cBEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(root,test_data_list,test_batch_size=16):\n",
        "  test_data = ChestXrayDataSet(root, test_data_list)\n",
        "  test_dataloader = DataLoader(test_data, batch_size=test_batch_size,\n",
        "                                shuffle=False,num_workers=2)\n",
        "  total_batch=len(test_data)/16\n",
        "  model = get_model()\n",
        "  if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "      torch.backends.cudnn.benchmark = True\n",
        "      print(\"using GPU\")\n",
        "  criterion = torch.nn.MSELoss()\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss = 0.\n",
        "  eval_acc = 0.\n",
        "  with torch.no_grad():\n",
        "    bar = tqdm(enumerate(test_dataloader), total=total_batch)\n",
        "    for i, (data, label) in bar:\n",
        "      batch_X = data.clone().detach()\n",
        "      batch_y = label.clone().detach()\n",
        "      if torch.cuda.is_available():\n",
        "        batch_X=batch_X.cuda()\n",
        "        batch_y=batch_y.cuda()\n",
        "      out=model(batch_X)\n",
        "      loss = criterion(out, batch_y)\n",
        "      eval_loss += loss.item()\n",
        "      # pred is the expect class\n",
        "      # batch_y is the true label\n",
        "      #pred = torch.max(out, 1)[1]\n",
        "      pred=getBinaryTensor(out)\n",
        "      test_correct = (pred == batch_y.view(-1)).sum()\n",
        "      eval_acc += test_correct.item()\n",
        "      print('Test_loss: ', eval_loss / len(test_data), 'Test acc: ', eval_acc / len(test_data))"
      ],
      "metadata": {
        "id": "gXm1viSQXNsK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(root,test_data_list)"
      ],
      "metadata": {
        "id": "KRD1l4N1qNd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}